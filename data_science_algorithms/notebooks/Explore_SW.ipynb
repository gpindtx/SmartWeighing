{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    df.data= pd.to_datetime(df.data, format='%Y%m%d%H%M%S')\n",
    "    df['day'] = df['data'].dt.day\n",
    "    df['Hour'] = df['data'].dt.hour\n",
    "    df['Minute'] = df['data'].dt.minute\n",
    "    df['Year'] = df['data'].dt.year\n",
    "    df['Month'] = df['data'].dt.month\n",
    "    \n",
    "    Year=df.Year.unique()[0]\n",
    "    Month=df.Month.unique()[0]\n",
    "    Day=df.day.unique()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Todos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados=pd.DataFrame()\n",
    "for i in range(1,11):\n",
    "    teste=pd.read_json('weighings_treated_partition'+str(i)+'.json')#+str(i)\n",
    "    dados=dados.append(teste, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dados.to_csv('all_weighings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (3,4,8,11,14,17,20,23,26) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "dados=pd.read_csv('all_weighings.csv').drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected object or value",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-bba74bda8e57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdados\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'IoT-Production-2020-05-20T15-49-19.382Z'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#.drop('Unnamed: 0', axis=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mread_json\u001b[0;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, lines, chunksize, compression)\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mjson_reader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    593\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshould_close\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_object_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_combine_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_object_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    718\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36m_get_object_parser\u001b[0;34m(self, json)\u001b[0m\n\u001b[1;32m    737\u001b[0m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"frame\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 739\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFrameParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"series\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 849\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_no_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    851\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36m_parse_no_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1091\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0morient\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m             self.obj = DataFrame(\n\u001b[0;32m-> 1093\u001b[0;31m                 \u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecise_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecise_float\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1094\u001b[0m             )\n\u001b[1;32m   1095\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0morient\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"split\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected object or value"
     ]
    }
   ],
   "source": [
    "dados=pd.read_json('IoT-Production-2020-05-20T15-49-19.382Z')#.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2615943, 30)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "details=pd.DataFrame(dados.dtypes, columns=['type'])\n",
    "details['#Nan']=dados.isnull().sum(axis = 0)\n",
    "details['#uniques']=dados.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "informaçoes\n",
    "- nr id unicos inferior a contagem, logo e queremos drop duplicates?\n",
    "- nr de id cells 0 unicos + nan > valoresunicos de pesagens..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### avaliar id iguais\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "validar_ids=dados.sort_values(['_id','cellId_0']).set_index(['_id','cellId_0']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "validar_ids=dados.sort_values(['_id'],ascending=False)#.set_index(['_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dados.groupby(['_id']).size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Avaliar contagem de variaveis para msm id = nºx que se repete id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validar_ids=dados.groupby('_id').count()#.apply(pd.DataFrame.sort_values, '_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "validar_ids.sort_values(by=['cellId_0','cellId_1','cellId_2','cellId_3','cellId_4','cellId_5'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maybe2=dados[dados['_id']=='5eb0761da4982500078f7abd']\n",
    "maybe2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Avaliar contagem de variaveis UNICAS para msm id = nºx que se repete id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validar_ids=dados.groupby('_id').nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validar_ids.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validar_ids.sort_values(by=['terminalSerialNumber'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maybe2=dados[dados['_id']=='5e8e79f931557300072fdafc']\n",
    "maybe2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "informaçoes\n",
    "- ha muitos duplicados ao nivel do id - deitar fora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_no_duplicates=dados.drop_duplicates()\n",
    "print(dados.shape)\n",
    "print(dados_no_duplicates.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_no_duplicates.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maybe2=dados_no_duplicates[dados_no_duplicates['_id']=='5e8e79f931557300072fdafc']\n",
    "maybe2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "informaçao:\n",
    "- como diferente tipos de dados ou casas decimais provocam duplicates, avaliar id unicos de pesagens e fazer inner join com dados\n",
    "- no fim so se pode ter 871549 pesagens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dados unicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_no_duplicates_id=dados.drop_duplicates(subset=['_id'])\n",
    "print(dados_no_duplicates_id.shape)\n",
    "#df.drop_duplicates(subset=['bio', 'center', 'outcome'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_no_duplicates_id.to_csv('weighings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados=pd.read_csv('weighings.csv').drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### avaliar combinaçoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validar_ids=dados.groupby('_id').nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validar_ids=dados.groupby('cellId_2').nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validar_ids.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "details=pd.DataFrame(dados.dtypes, columns=['type'])\n",
    "details['#Nan']=dados.isnull().sum(axis = 0)\n",
    "details['#uniques']=dados.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "details['valida']=details['#uniques']+details['#Nan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Informaçoes:\n",
    "- para qq groupby de celula, o maximo de unicos e sempre 1, ou seja a combinaçao cel 0-1-2-3... e sempre unica. um id da celula 1 so da para a celula com id0 certa\n",
    "- confirmado pelo numeor de unicos+nan ser igual ao totla de pesagens feitas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grave:\n",
    "- cada nao ha varias pesagens diferentes com o msm id de celulas, ie, nenhuma celeua com mais que uma pesagem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transformaçao dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- avalair qts pontes têm 2,4,6,8 celulas\n",
    "- avaliar se ha pontes com celulas impar\n",
    "- transformaçao das datas + idade da celula\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Avaliar nº pesagens  para pontes com variavel nº de celulas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## avalair qts celulas\n",
    "dados_8=dados[dados['cellId_0'].notnull() & dados['cellId_1'].notnull() & dados['cellId_2'].notnull() & dados['cellId_3'].notnull() & dados['cellId_4'].notnull() & dados['cellId_5'].notnull() & dados['cellId_6'].notnull() & dados['cellId_7'].notnull()]\n",
    "print('nº weighing with 8 functional cells:' + str(dados_8.shape[0]))\n",
    "\n",
    "dados_7=dados[dados['cellId_0'].notnull() & dados['cellId_1'].notnull() & dados['cellId_2'].notnull() & dados['cellId_3'].notnull() & dados['cellId_4'].notnull() & dados['cellId_5'].notnull() & dados['cellId_6'].notnull() ]\n",
    "print('nº weighing with 7 functional cells:' + str(dados_7.shape[0]))\n",
    "\n",
    "dados_6=dados[dados['cellId_0'].notnull() & dados['cellId_1'].notnull() & dados['cellId_2'].notnull() & dados['cellId_3'].notnull() & dados['cellId_4'].notnull() & dados['cellId_5'].notnull()]\n",
    "print('nº weighing with 6 functional cells:' + str(dados_6.shape[0]))\n",
    "\n",
    "dados_5=dados[dados['cellId_0'].notnull() & dados['cellId_1'].notnull() & dados['cellId_2'].notnull() & dados['cellId_3'].notnull() & dados['cellId_4'].notnull()]\n",
    "print('nº weighing with 5 functional cells:' + str(dados_5.shape[0]))\n",
    "\n",
    "dados_4=dados[dados['cellId_0'].notnull() & dados['cellId_1'].notnull() & dados['cellId_2'].notnull() & dados['cellId_3'].notnull()]\n",
    "print('nº weighing with 4 functional cells:' + str(dados_4.shape[0]))\n",
    "\n",
    "dados_3=dados[dados['cellId_0'].notnull() & dados['cellId_1'].notnull() & dados['cellId_2'].notnull()]\n",
    "print('nº weighing with 3 functional cells:' + str(dados_3.shape[0]))\n",
    "\n",
    "dados_2=dados[dados['cellId_0'].notnull() & dados['cellId_1'].notnull()]\n",
    "print('nº weighing with 2 functional cells:' + str(dados_2.shape[0]))\n",
    "\n",
    "dados_1=dados[dados['cellId_0'].notnull()]\n",
    "print('nº weighing with 1 functional cells:' + str(dados_1.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Há pesagens para pontes com nº impar\n",
    "- Há 29258 pesagens sem ponte nenhuma\n",
    "- Para alem de todas as comiançoes de id de celulas serem unicas, nao ha cenarios de falhar celula 0 e ter celula1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = dados.append(dados_1)\n",
    "combined=combined[~combined.index.duplicated(keep=False)]\n",
    "print(combined.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "details=pd.DataFrame(combined.nunique(), columns=['nº uniques with cell0 Nan'])\n",
    "details['n_uniques with cell0']=dados_1.nunique()\n",
    "details['n_uniques in all']=dados.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## nao ha cenario de nao haver cell 0 e ter cell 1\n",
    "teste=dados[dados['cellId_0'].isnull()]\n",
    "teste['cellId_2'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste=dados[dados['cellId_1'].isnull()]\n",
    "teste['cellId_3'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    df.data= pd.to_datetime(df.data, format='%Y%m%d%H%M%S')\n",
    "    df['day'] = df['data'].dt.day\n",
    "    df['Hour'] = df['data'].dt.hour\n",
    "    df['Minute'] = df['data'].dt.minute\n",
    "    df['Year'] = df['data'].dt.year\n",
    "    df['Month'] = df['data'].dt.month\n",
    "    \n",
    "    Year=df.Year.unique()[0]\n",
    "    Month=df.Month.unique()[0]\n",
    "    Day=df.day.unique()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados['data']= pd.to_datetime(dados.timestamp, format='%Y-%m-%d %H:%M:%S.%f')#'%Y%m%d%H%M%S%S%f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados['day'] = dados['data'].dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## teste bascio PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(data,categorical_features):\n",
    "    categorical_names = {}\n",
    "    for feature in categorical_features:\n",
    "        le = sklearn.preprocessing.LabelEncoder()\n",
    "        #le.fit(frame2[:, feature])\n",
    "        #train_numpy_array[:, feature] = le.fit_transform(train_numpy_array[:, feature])\n",
    "        data[:, feature] = le.fit_transform(data[:, feature])\n",
    "        categorical_names[feature] = le.classes_\n",
    "    return data, categorical_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prePCA.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prePCA=dados.set_index('_id').drop('timestamp', axis=1)\n",
    "categorical_features = [0,1,4,5,20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Converter data em idade\n",
    "- transformar id de celulas em se tem 2,4,6,8, impares\n",
    "- transformar ids em se e a combinaçao 1 ,2, 3 ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA, IncrementalPCA\n",
    "pcat = PCA()\n",
    "principalComponentsT = pcat.fit_transform(dados)\n",
    "pesos= pcat.explained_variance_ratio_\n",
    "loadingT=pcat.components_.T * np.sqrt(pcat.explained_variance_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
